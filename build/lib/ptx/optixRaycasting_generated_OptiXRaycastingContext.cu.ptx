//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26907403
// Cuda compilation tools, release 10.1, V10.1.243
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_30
.address_size 64

	// .globl	_Z9intersecti
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 vertex_buffer[1];
.global .align 1 .b8 index_buffer[1];
.global .align 1 .b8 texcoord_buffer[1];
.global .align 8 .b8 hit_attr[40];
.global .align 4 .b8 ray[36];
.global .align 8 .b8 hit_prd[40];
.global .texref mask_sampler;
.global .align 4 .u32 launch_index;
.global .align 4 .b8 top_object[4];
.global .align 1 .b8 hits[1];
.global .align 1 .b8 rays[1];
.global .align 4 .b8 _ZN21rti_internal_typeinfo8hit_attrE[8] = {82, 97, 121, 0, 40, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3rayE[8] = {82, 97, 121, 0, 36, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo7hit_prdE[8] = {82, 97, 121, 0, 40, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo12launch_indexE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10top_objectE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;
.global .align 1 .b8 _ZN21rti_internal_typename8hit_attrE[4] = {72, 105, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3rayE[11] = {111, 112, 116, 105, 120, 58, 58, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_typename7hit_prdE[4] = {72, 105, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename12launch_indexE[13] = {117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10top_objectE[9] = {114, 116, 79, 98, 106, 101, 99, 116, 0};
.global .align 4 .u32 _ZN21rti_internal_typeenum8hit_attrE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3rayE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum7hit_prdE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum12launch_indexE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10top_objectE = 4919;
.global .align 1 .b8 _ZN21rti_internal_semantic8hit_attrE[19] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 104, 105, 116, 95, 97, 116, 116, 114, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic3rayE[13] = {114, 116, 67, 117, 114, 114, 101, 110, 116, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic7hit_prdE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic12launch_indexE[14] = {114, 116, 76, 97, 117, 110, 99, 104, 73, 110, 100, 101, 120, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic10top_objectE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8hit_attrE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3rayE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation7hit_prdE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation12launch_indexE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10top_objectE[1];
.global .align 1 .b8 $str[44] = {67, 97, 117, 103, 104, 116, 32, 101, 120, 99, 101, 112, 116, 105, 111, 110, 32, 48, 120, 37, 88, 32, 97, 116, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 40, 37, 100, 41, 10, 0};

.visible .entry _Z9intersecti(
	.param .u32 _Z9intersecti_param_0
)
{
	.reg .pred 	%p<12>;
	.reg .f32 	%f<97>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<55>;


	ld.param.u32 	%r1, [_Z9intersecti_param_0];
	cvt.s64.s32	%rd6, %r1;
	mov.u64 	%rd28, index_buffer;
	cvta.global.u64 	%rd5, %rd28;
	mov.u32 	%r8, 1;
	mov.u32 	%r9, 12;
	mov.u64 	%rd27, 0;
	// inline asm
	call (%rd4), _rt_buffer_get_64, (%rd5, %r8, %r9, %rd6, %rd27, %rd27, %rd27);
	// inline asm
	ld.s32 	%rd12, [%rd4];
	mov.u64 	%rd29, vertex_buffer;
	cvta.global.u64 	%rd11, %rd29;
	ld.s32 	%rd18, [%rd4+4];
	ld.s32 	%rd24, [%rd4+8];
	// inline asm
	call (%rd10), _rt_buffer_get_64, (%rd11, %r8, %r9, %rd12, %rd27, %rd27, %rd27);
	// inline asm
	ld.f32 	%f14, [%rd10];
	ld.f32 	%f15, [%rd10+4];
	ld.f32 	%f16, [%rd10+8];
	// inline asm
	call (%rd16), _rt_buffer_get_64, (%rd11, %r8, %r9, %rd18, %rd27, %rd27, %rd27);
	// inline asm
	ld.f32 	%f17, [%rd16];
	ld.f32 	%f18, [%rd16+4];
	ld.f32 	%f19, [%rd16+8];
	// inline asm
	call (%rd22), _rt_buffer_get_64, (%rd11, %r8, %r9, %rd24, %rd27, %rd27, %rd27);
	// inline asm
	sub.ftz.f32 	%f20, %f17, %f14;
	sub.ftz.f32 	%f21, %f18, %f15;
	sub.ftz.f32 	%f22, %f19, %f16;
	ld.f32 	%f23, [%rd22];
	sub.ftz.f32 	%f24, %f14, %f23;
	ld.f32 	%f25, [%rd22+4];
	sub.ftz.f32 	%f26, %f15, %f25;
	ld.f32 	%f27, [%rd22+8];
	sub.ftz.f32 	%f28, %f16, %f27;
	mul.ftz.f32 	%f29, %f22, %f26;
	mul.ftz.f32 	%f30, %f21, %f28;
	sub.ftz.f32 	%f1, %f29, %f30;
	mul.ftz.f32 	%f31, %f20, %f28;
	mul.ftz.f32 	%f32, %f22, %f24;
	sub.ftz.f32 	%f2, %f31, %f32;
	mul.ftz.f32 	%f33, %f21, %f24;
	mul.ftz.f32 	%f34, %f20, %f26;
	sub.ftz.f32 	%f3, %f33, %f34;
	ld.global.f32 	%f35, [ray+12];
	ld.global.f32 	%f36, [ray+16];
	mul.ftz.f32 	%f37, %f36, %f2;
	fma.rn.ftz.f32 	%f38, %f35, %f1, %f37;
	ld.global.f32 	%f39, [ray+20];
	fma.rn.ftz.f32 	%f40, %f39, %f3, %f38;
	rcp.approx.ftz.f32 	%f41, %f40;
	ld.global.f32 	%f42, [ray];
	sub.ftz.f32 	%f43, %f14, %f42;
	ld.global.f32 	%f44, [ray+4];
	sub.ftz.f32 	%f45, %f15, %f44;
	ld.global.f32 	%f46, [ray+8];
	sub.ftz.f32 	%f47, %f16, %f46;
	mul.ftz.f32 	%f48, %f41, %f43;
	mul.ftz.f32 	%f49, %f41, %f45;
	mul.ftz.f32 	%f50, %f41, %f47;
	mul.ftz.f32 	%f51, %f36, %f50;
	mul.ftz.f32 	%f52, %f49, %f39;
	sub.ftz.f32 	%f53, %f51, %f52;
	mul.ftz.f32 	%f54, %f48, %f39;
	mul.ftz.f32 	%f55, %f50, %f35;
	sub.ftz.f32 	%f56, %f54, %f55;
	mul.ftz.f32 	%f57, %f49, %f35;
	mul.ftz.f32 	%f58, %f48, %f36;
	sub.ftz.f32 	%f59, %f57, %f58;
	mul.ftz.f32 	%f60, %f26, %f56;
	fma.rn.ftz.f32 	%f61, %f24, %f53, %f60;
	fma.rn.ftz.f32 	%f4, %f28, %f59, %f61;
	mul.ftz.f32 	%f62, %f21, %f56;
	fma.rn.ftz.f32 	%f63, %f20, %f53, %f62;
	fma.rn.ftz.f32 	%f5, %f22, %f59, %f63;
	mul.ftz.f32 	%f64, %f2, %f49;
	fma.rn.ftz.f32 	%f65, %f1, %f48, %f64;
	fma.rn.ftz.f32 	%f6, %f3, %f50, %f65;
	ld.global.f32 	%f66, [ray+32];
	setp.geu.ftz.f32	%p1, %f6, %f66;
	ld.global.f32 	%f67, [ray+28];
	setp.leu.ftz.f32	%p2, %f6, %f67;
	or.pred  	%p3, %p1, %p2;
	setp.ltu.ftz.f32	%p4, %f4, 0f00000000;
	or.pred  	%p5, %p3, %p4;
	setp.ltu.ftz.f32	%p6, %f5, 0f00000000;
	or.pred  	%p7, %p5, %p6;
	add.ftz.f32 	%f68, %f4, %f5;
	setp.gtu.ftz.f32	%p8, %f68, 0f3F800000;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	BB0_5;

	// inline asm
	call (%r10), _rt_potential_intersection, (%f6);
	// inline asm
	setp.eq.s32	%p10, %r10, 0;
	@%p10 bra 	BB0_5;

	mul.ftz.f32 	%f72, %f2, %f2;
	fma.rn.ftz.f32 	%f73, %f1, %f1, %f72;
	fma.rn.ftz.f32 	%f74, %f3, %f3, %f73;
	rsqrt.approx.ftz.f32 	%f75, %f74;
	mul.ftz.f32 	%f7, %f1, %f75;
	mul.ftz.f32 	%f8, %f2, %f75;
	mul.ftz.f32 	%f9, %f3, %f75;
	mov.u64 	%rd35, texcoord_buffer;
	cvta.global.u64 	%rd34, %rd35;
	mov.u32 	%r12, 8;
	// inline asm
	call (%rd30, %rd31, %rd32, %rd33), _rt_buffer_get_size_64, (%rd34, %r8, %r12);
	// inline asm
	cvt.u32.u64	%r13, %rd30;
	setp.eq.s32	%p11, %r13, 0;
	mov.f32 	%f95, 0f00000000;
	mov.f32 	%f96, %f95;
	@%p11 bra 	BB0_4;

	// inline asm
	call (%rd36), _rt_buffer_get_64, (%rd34, %r8, %r12, %rd12, %rd27, %rd27, %rd27);
	// inline asm
	ld.v2.f32 	{%f76, %f77}, [%rd36];
	// inline asm
	call (%rd42), _rt_buffer_get_64, (%rd34, %r8, %r12, %rd18, %rd27, %rd27, %rd27);
	// inline asm
	ld.v2.f32 	{%f80, %f81}, [%rd42];
	// inline asm
	call (%rd48), _rt_buffer_get_64, (%rd34, %r8, %r12, %rd24, %rd27, %rd27, %rd27);
	// inline asm
	ld.v2.f32 	{%f84, %f85}, [%rd48];
	mul.ftz.f32 	%f88, %f5, %f84;
	mul.ftz.f32 	%f89, %f5, %f85;
	fma.rn.ftz.f32 	%f90, %f4, %f80, %f88;
	fma.rn.ftz.f32 	%f91, %f4, %f81, %f89;
	mov.f32 	%f92, 0f3F800000;
	sub.ftz.f32 	%f93, %f92, %f4;
	sub.ftz.f32 	%f94, %f93, %f5;
	fma.rn.ftz.f32 	%f95, %f94, %f76, %f90;
	fma.rn.ftz.f32 	%f96, %f94, %f77, %f91;

BB0_4:
	mov.u32 	%r21, 0;
	mov.b32 	 %r22, %f6;
	st.global.v2.u32 	[hit_attr], {%r22, %r1};
	st.global.v2.f32 	[hit_attr+8], {%f4, %f5};
	st.global.v2.f32 	[hit_attr+16], {%f7, %f8};
	st.global.f32 	[hit_attr+24], %f9;
	st.global.v2.f32 	[hit_attr+32], {%f95, %f96};
	// inline asm
	call (%r20), _rt_report_intersection, (%r21);
	// inline asm

BB0_5:
	ret;
}

	// .globl	_Z6boundsiPf
.visible .entry _Z6boundsiPf(
	.param .u32 _Z6boundsiPf_param_0,
	.param .u64 _Z6boundsiPf_param_1
)
{
	.reg .f32 	%f<22>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<29>;


	ld.param.u64 	%rd25, [_Z6boundsiPf_param_1];
	ld.param.s32 	%rd3, [_Z6boundsiPf_param_0];
	mov.u64 	%rd26, index_buffer;
	cvta.global.u64 	%rd2, %rd26;
	mov.u32 	%r7, 1;
	mov.u32 	%r8, 12;
	mov.u64 	%rd24, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r7, %r8, %rd3, %rd24, %rd24, %rd24);
	// inline asm
	ld.s32 	%rd9, [%rd1];
	mov.u64 	%rd27, vertex_buffer;
	cvta.global.u64 	%rd8, %rd27;
	ld.s32 	%rd15, [%rd1+4];
	ld.s32 	%rd21, [%rd1+8];
	// inline asm
	call (%rd7), _rt_buffer_get_64, (%rd8, %r7, %r8, %rd9, %rd24, %rd24, %rd24);
	// inline asm
	ld.f32 	%f1, [%rd7];
	ld.f32 	%f2, [%rd7+4];
	ld.f32 	%f3, [%rd7+8];
	// inline asm
	call (%rd13), _rt_buffer_get_64, (%rd8, %r7, %r8, %rd15, %rd24, %rd24, %rd24);
	// inline asm
	ld.f32 	%f4, [%rd13];
	ld.f32 	%f5, [%rd13+4];
	ld.f32 	%f6, [%rd13+8];
	// inline asm
	call (%rd19), _rt_buffer_get_64, (%rd8, %r7, %r8, %rd21, %rd24, %rd24, %rd24);
	// inline asm
	ld.f32 	%f7, [%rd19];
	ld.f32 	%f8, [%rd19+4];
	ld.f32 	%f9, [%rd19+8];
	cvta.to.global.u64 	%rd28, %rd25;
	min.ftz.f32 	%f10, %f1, %f4;
	min.ftz.f32 	%f11, %f2, %f5;
	min.ftz.f32 	%f12, %f3, %f6;
	min.ftz.f32 	%f13, %f10, %f7;
	min.ftz.f32 	%f14, %f11, %f8;
	min.ftz.f32 	%f15, %f12, %f9;
	st.global.f32 	[%rd28], %f13;
	st.global.f32 	[%rd28+4], %f14;
	st.global.f32 	[%rd28+8], %f15;
	max.ftz.f32 	%f16, %f1, %f4;
	max.ftz.f32 	%f17, %f2, %f5;
	max.ftz.f32 	%f18, %f3, %f6;
	max.ftz.f32 	%f19, %f16, %f7;
	max.ftz.f32 	%f20, %f17, %f8;
	max.ftz.f32 	%f21, %f18, %f9;
	st.global.f32 	[%rd28+12], %f19;
	st.global.f32 	[%rd28+16], %f20;
	st.global.f32 	[%rd28+20], %f21;
	ret;
}

	// .globl	_Z11closest_hitv
.visible .entry _Z11closest_hitv(

)
{
	.reg .b32 	%r<21>;


	ld.global.v2.u32 	{%r1, %r2}, [hit_attr];
	ld.global.v2.u32 	{%r5, %r6}, [hit_attr+8];
	ld.global.v2.u32 	{%r9, %r10}, [hit_attr+16];
	ld.global.v2.u32 	{%r13, %r14}, [hit_attr+24];
	ld.global.v2.u32 	{%r17, %r18}, [hit_attr+32];
	st.global.v2.u32 	[hit_prd], {%r1, %r2};
	st.global.v2.u32 	[hit_prd+8], {%r5, %r6};
	st.global.v2.u32 	[hit_prd+16], {%r9, %r10};
	st.global.v2.u32 	[hit_prd+24], {%r13, %r14};
	st.global.v2.u32 	[hit_prd+32], {%r17, %r18};
	ret;
}

	// .globl	_Z7any_hitv
.visible .entry _Z7any_hitv(

)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<6>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<2>;


	ld.global.v2.f32 	{%f1, %f2}, [hit_attr+32];
	tex.2d.v4.u32.f32	{%r1, %r2, %r3, %r4}, [mask_sampler, {%f1, %f2}];
	mov.b32 	 %f5, %r1;
	setp.geu.ftz.f32	%p1, %f5, 0f3F000000;
	@%p1 bra 	BB3_2;

	// inline asm
	call _rt_ignore_intersection, ();
	// inline asm

BB3_2:
	ret;
}

	// .globl	_Z7ray_genv
.visible .entry _Z7ray_genv(

)
{
	.local .align 8 .b8 	__local_depot4[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<11>;
	.reg .b32 	%r<32>;
	.reg .b64 	%rd<17>;


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	mov.u32 	%r10, -1;
	mov.u32 	%r11, -1082130432;
	add.u64 	%rd7, %SP, 0;
	add.u64 	%rd14, %SPL, 0;
	st.local.v2.u32 	[%rd14], {%r11, %r10};
	mov.f32 	%f9, 0f00000000;
	st.local.v2.f32 	[%rd14+8], {%f9, %f9};
	mov.f32 	%f10, 0f3F800000;
	st.local.v2.f32 	[%rd14+16], {%f10, %f9};
	mov.u32 	%r6, 0;
	st.local.u32 	[%rd14+24], %r6;
	ld.global.u32 	%rd3, [launch_index];
	mov.u64 	%rd15, rays;
	cvta.global.u64 	%rd2, %rd15;
	mov.u32 	%r8, 1;
	mov.u32 	%r2, 32;
	mov.u64 	%rd13, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r8, %r2, %rd3, %rd13, %rd13, %rd13);
	// inline asm
	ld.f32 	%f1, [%rd1];
	ld.f32 	%f2, [%rd1+4];
	ld.f32 	%f3, [%rd1+8];
	ld.f32 	%f7, [%rd1+12];
	ld.f32 	%f4, [%rd1+16];
	ld.f32 	%f5, [%rd1+20];
	ld.f32 	%f6, [%rd1+24];
	ld.f32 	%f8, [%rd1+28];
	ld.global.u32 	%r3, [top_object];
	mov.u32 	%r5, 255;
	mov.u32 	%r9, 40;
	// inline asm
	call _rt_trace_mask_flags_64, (%r3, %f1, %f2, %f3, %f4, %f5, %f6, %r6, %f7, %f8, %r5, %r6, %rd7, %r9);
	// inline asm
	ld.global.u32 	%rd10, [launch_index];
	mov.u64 	%rd16, hits;
	cvta.global.u64 	%rd9, %rd16;
	// inline asm
	call (%rd8), _rt_buffer_get_64, (%rd9, %r8, %r9, %rd10, %rd13, %rd13, %rd13);
	// inline asm
	ld.local.v2.u32 	{%r12, %r13}, [%rd14];
	ld.local.v2.u32 	{%r16, %r17}, [%rd14+8];
	ld.local.v2.u32 	{%r20, %r21}, [%rd14+16];
	ld.local.v2.u32 	{%r24, %r25}, [%rd14+24];
	ld.local.v2.u32 	{%r28, %r29}, [%rd14+32];
	st.v2.u32 	[%rd8], {%r12, %r13};
	st.v2.u32 	[%rd8+8], {%r16, %r17};
	st.v2.u32 	[%rd8+16], {%r20, %r21};
	st.v2.u32 	[%rd8+24], {%r24, %r25};
	st.v2.u32 	[%rd8+32], {%r28, %r29};
	ret;
}

	// .globl	_Z9exceptionv
.visible .entry _Z9exceptionv(

)
{
	.local .align 8 .b8 	__local_depot5[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<12>;


	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	// inline asm
	call (%r3), _rt_get_exception_code, ();
	// inline asm
	ld.global.u32 	%r2, [launch_index];
	// inline asm
	call (%r4), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p1, %r4, 0;
	@%p1 bra 	BB5_2;

	add.u64 	%rd1, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	st.local.v2.u32 	[%rd2], {%r3, %r2};
	mov.u64 	%rd3, $str;
	cvta.global.u64 	%rd4, %rd3;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r5, [retval0+0];
	
	//{
	}// Callseq End 0

BB5_2:
	ld.global.u32 	%rd7, [launch_index];
	mov.u64 	%rd11, hits;
	cvta.global.u64 	%rd6, %rd11;
	mov.u32 	%r6, 1;
	mov.u32 	%r7, 40;
	mov.u64 	%rd10, 0;
	// inline asm
	call (%rd5), _rt_buffer_get_64, (%rd6, %r6, %r7, %rd7, %rd10, %rd10, %rd10);
	// inline asm
	mov.u32 	%r8, -1;
	mov.u32 	%r9, -1082130432;
	st.v2.u32 	[%rd5], {%r9, %r8};
	mov.f32 	%f1, 0f00000000;
	st.v2.f32 	[%rd5+8], {%f1, %f1};
	mov.f32 	%f2, 0f3F800000;
	st.v2.f32 	[%rd5+16], {%f2, %f1};
	mov.u32 	%r10, 0;
	st.u32 	[%rd5+24], %r10;
	ret;
}


